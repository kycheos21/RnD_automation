import os
import sys
import time
import json
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager

# UTF-8 ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# í”„ë¡œì íŠ¸ src ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# ì„¤ì • íŒŒì¼ import
try:
    from utils.config_reader import get_search_keywords, get_ui_selector, get_page_unit_target_value
except ImportError as e:
    print(f"âš ï¸ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print("   ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

def extract_uid_from_url(url):
    """ìƒì„¸_URLì—ì„œ roRndUid ì¶”ì¶œ"""
    try:
        match = re.search(r'roRndUid=(\d+)', url)
        return match.group(1) if match else ""
    except Exception:
        return ""

def crawl_announcement_list(driver, target_count=30):
    """
    NTIS ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê³µê³  ë¦¬ìŠ¤íŠ¸ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
    
    ì¤‘ìš”ì‚¬í•­:
    - ì ‘ìˆ˜ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ìµœì‹  ê³µê³ ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ í•¨
    - roRndUidë¥¼ ê³ ìœ  ì‹ë³„ìë¡œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ íŒë³„
    """
    print(f"\nğŸ“‹ ê³µê³  ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹œì‘ (ëª©í‘œ: {target_count}ê°œ)")
    print("=" * 50)
    
    try:
        # 1. ê²€ìƒ‰ ê²°ê³¼ í…Œì´ë¸”ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°
        print("1ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°...")
        table = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "table.basic_list"))
        )
        print("   âœ… basic_list í…Œì´ë¸” ë°œê²¬")

        # 2. í…Œì´ë¸”ì˜ ëª¨ë“  í–‰(rows)ì„ ìš°ì„  ìˆ˜ì§‘
        rows = table.find_elements(By.CSS_SELECTOR, "tbody tr")
        print(f"   ğŸ“Š ë°œê²¬ëœ ê³µê³  í•­ëª©: {len(rows)}ê°œ")
        if not rows:
            print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

        # 3. ëª¨ë“  í–‰ì˜ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
        print("\n2ï¸âƒ£ ëª¨ë“  ê³µê³  ì •ë³´ ì„ì‹œ ì¶”ì¶œ ì¤‘...")
        all_rows_data = []
        for i, row in enumerate(rows):
            try:
                cells = row.find_elements(By.TAG_NAME, "td")
                if len(cells) < 8:
                    continue
                
                item_data = {
                    "í˜„í™©": cells[2].find_element(By.TAG_NAME, "span").text.strip(),
                    "ê³µê³ ëª…": cells[3].find_element(By.TAG_NAME, "a").text.strip(),
                    "ìƒì„¸_URL": cells[3].find_element(By.TAG_NAME, "a").get_attribute('href'),
                    "ë¶€ì²˜ëª…": cells[4].text.strip(),
                    "ì ‘ìˆ˜ì¼": cells[5].text.strip(),
                    "ë§ˆê°ì¼": cells[6].text.strip(),
                }
                all_rows_data.append(item_data)
            except Exception as e:
                print(f"   âŒ {i+1}ë²ˆì§¸ í–‰ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                continue
        
        # 4. 'ì ‘ìˆ˜ì¼'ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (ìµœì‹  ê³µê³ ê°€ ìœ„ë¡œ ì˜¤ë„ë¡)
        print("\n3ï¸âƒ£ ì ‘ìˆ˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì •ë ¬ ì¤‘...")
        
        def parse_date_for_sort(date_str):
            """ì •ë ¬ì„ ìœ„í•œ ë‚ ì§œ íŒŒì‹± (YYYY.MM.DD í˜•ì‹)"""
            try:
                return datetime.strptime(date_str, "%Y.%m.%d")
            except:
                return datetime.min  # íŒŒì‹± ì‹¤íŒ¨ì‹œ ê°€ì¥ ì˜¤ë˜ëœ ë‚ ì§œë¡œ ì²˜ë¦¬
        
        sorted_data = sorted(all_rows_data, key=lambda x: parse_date_for_sort(x['ì ‘ìˆ˜ì¼']), reverse=True)
        print("   âœ… ì ‘ìˆ˜ì¼ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ ì™„ë£Œ!")
        
        # 5. ëª©í‘œ ê°œìˆ˜ë§Œí¼ ìµœì¢… ë°ì´í„° ì„ íƒ
        final_data = sorted_data[:target_count]

        print(f"\n4ï¸âƒ£ í¬ë¡¤ë§ ì™„ë£Œ! (ì„±ê³µ: {len(final_data)}ê°œ)")
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥ (ì ‘ìˆ˜ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ìƒíƒœ)
        print("\nğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ (ì ‘ìˆ˜ì¼ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ):")
        print("-" * 50)
        for i, data in enumerate(final_data[:5]):  # ì²˜ìŒ 5ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
            print(f"{i+1}. [{data['í˜„í™©']}] {data['ê³µê³ ëª…'][:60]}...")
            print(f"    ì ‘ìˆ˜ì¼: {data['ì ‘ìˆ˜ì¼']} | ë¶€ì²˜: {data['ë¶€ì²˜ëª…']}")
        
        if len(final_data) > 5:
            print(f"... ì™¸ {len(final_data) - 5}ê°œ í•­ëª©")
        
        return final_data

    except Exception as e:
        print(f"   âŒ í¬ë¡¤ë§ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

def search_with_keyword(driver, keyword):
    """ì‹¤ì œ ê²€ìƒ‰ ê¸°ëŠ¥"""
    print(f"\nğŸ” '{keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ê²€ìƒ‰ì°½ ì°¾ê¸° (ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„)
    print("1ï¸âƒ£ ê²€ìƒ‰ì°½ ì°¾ê¸° ì¤‘...")
    
    search_input = None
    possible_search_selectors = [
        (By.CSS_SELECTOR, "input[placeholder*='í‚¤ì›Œë“œ']"),
        (By.NAME, "searchKeyword"),
        (By.ID, "searchKeyword"),
        (By.CSS_SELECTOR, "input[type='text']")
    ]
    
    for by_type, selector in possible_search_selectors:
        try:
            search_input = WebDriverWait(driver, 2).until(
                EC.presence_of_element_located((by_type, selector))
            )
            print(f"   âœ… ê²€ìƒ‰ì°½ ë°œê²¬: {by_type} = '{selector}'")
            break
        except:
            continue
    
    if not search_input:
        print("   âŒ ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return False
    
    # ê²€ìƒ‰ì–´ ì…ë ¥
    print(f"2ï¸âƒ£ '{keyword}' í‚¤ì›Œë“œ ì…ë ¥ ì¤‘...")
    search_input.clear()
    search_input.send_keys(keyword)
    print("   âœ… í‚¤ì›Œë“œ ì…ë ¥ ì™„ë£Œ")
    
    # ì ì‹œ ëŒ€ê¸°
    time.sleep(1)
    
    # ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ 30ê°œ ì„¤ì • (ê²€ìƒ‰ ì „ì—!)
    print("3ï¸âƒ£ ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ 30ê°œ ì„¤ì • ì¤‘...")
    page_unit_success = set_page_unit_to_30(driver)
    
    if not page_unit_success:
        print("   âš ï¸ ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ê°’ìœ¼ë¡œ ì§„í–‰")
    
    time.sleep(1)
    
    # ê²€ìƒ‰ ë²„íŠ¼ ì°¾ê¸° ë° í´ë¦­ (ì •í™•í•œ ì…€ë ‰í„° ì‚¬ìš©)
    print("4ï¸âƒ£ ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì¤‘...")
    
    # onclick="javascript: fn_search('1', ''); return false;" ì™€ class="button blue"ë¥¼ ê°€ì§„ a íƒœê·¸
    search_button = WebDriverWait(driver, 5).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "a.button.blue[onclick*='fn_search']"))
    )
    print("   âœ… ê²€ìƒ‰ ë²„íŠ¼ ë°œê²¬: a.button.blue[onclick*='fn_search']")
    search_button.click()
    print("   âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
    
    # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
    print("5ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°...")
    time.sleep(3)
    
    # í˜„ì¬ URL í™•ì¸
    current_url = driver.current_url
    print(f"   ğŸ“ ê²€ìƒ‰ í›„ URL: {current_url}")
    
    # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
    page_source = driver.page_source.lower()
    result_indicators = ['ê²€ìƒ‰ê²°ê³¼', 'ê²€ìƒ‰ ê²°ê³¼', 'search result', keyword.lower()]
    
    found_results = []
    for indicator in result_indicators:
        if indicator in page_source:
            found_results.append(indicator)
    
    if found_results:
        print(f"   âœ… ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ í™•ì¸ë¨: {', '.join(found_results)}")
        
        # ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        os.makedirs("output", exist_ok=True)
        driver.save_screenshot(f"output/search_result_{keyword}.png")
        print(f"   ğŸ“¸ ê²€ìƒ‰ ê²°ê³¼ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: output/search_result_{keyword}.png")
        
        return True
    else:
        print("   âš ï¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return False

def set_page_unit_to_30(driver):
    """ë¦¬ìŠ¤íŠ¸ í‘œì‹œ ê°œìˆ˜ë¥¼ 30ê°œë¡œ ì„¤ì •"""
    print("ğŸ“Š ë¦¬ìŠ¤íŠ¸ í‘œì‹œ ê°œìˆ˜ ì„¤ì •")
    print("-" * 30)
    
    # í˜ì´ì§€ ë‹¨ìœ„ ë“œë¡­ë‹¤ìš´ ì°¾ê¸°
    print("1ï¸âƒ£ í˜ì´ì§€ ë‹¨ìœ„ ë“œë¡­ë‹¤ìš´ ì°¾ê¸°...")
    page_unit_select = WebDriverWait(driver, 5).until(
        EC.presence_of_element_located((By.NAME, "pageUnit"))
    )
    print("   âœ… pageUnit ë“œë¡­ë‹¤ìš´ ë°œê²¬")
    
    # Select ê°ì²´ ìƒì„±
    select = Select(page_unit_select)
    print("2ï¸âƒ£ 30ê°œ ì˜µì…˜ ì„ íƒ ì¤‘...")
    
    # 30 ì„ íƒ
    select.select_by_value("30")
    print("   âœ… 30ê°œ ì˜µì…˜ ì„ íƒ ì™„ë£Œ")
    
    # ì„ íƒëœ ê°’ í™•ì¸
    selected_option = select.first_selected_option
    print(f"   ğŸ“Š í˜„ì¬ ì„ íƒëœ ê°’: {selected_option.get_attribute('value')}ê°œ")
    
    return True

def create_chrome_driver():
    """Chrome WebDriver ìƒì„±"""
    print("ğŸŒ Chrome ë¸Œë¼ìš°ì € ì„¤ì • ì¤‘...")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument("--window-size=1200,800")
    
    # ChromeDriver ì„œë¹„ìŠ¤ ì„¤ì •
    service = Service(ChromeDriverManager().install())
    
    # WebDriver ìƒì„±
    driver = webdriver.Chrome(service=service, options=chrome_options)
    print("   âœ… Chrome ë¸Œë¼ìš°ì € ì¤€ë¹„ ì™„ë£Œ")
    
    return driver

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ NTIS ê³µê³  í¬ë¡¤ë§ ì‹œì‘")
    print("=" * 50)
    
    driver = None
    
    try:
        # 1. ë¸Œë¼ìš°ì € ì‹œì‘
        driver = create_chrome_driver()
        
        # 2. NTIS ì‚¬ì´íŠ¸ ì ‘ì†
        print("\nğŸŒ NTIS ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘...")
        
        # ì •í™•í•œ NTIS êµ­ê°€R&Dí†µí•©ê³µê³  URL
        target_url = "https://www.ntis.go.kr/rndgate/eg/un/ra/mng.do"
        print(f"   ğŸ¯ ëª©í‘œ URL: {target_url}")
        
        # ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
        max_retries = 3
        for attempt in range(1, max_retries + 1):
            try:
                print(f"   ì‹œë„ {attempt}/{max_retries}...")
                driver.get(target_url)
                
                # document.readyStateê°€ completeê°€ ë  ë•Œê¹Œì§€ ëŒ€ê¸°
                print("   í˜ì´ì§€ ë¡œë”© ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                WebDriverWait(driver, 20).until(
                    lambda d: d.execute_script("return document.readyState") == "complete"
                )
                print("   âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ!")
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ íƒˆì¶œ
                
            except Exception as e:
                print(f"   âš ï¸ ì‹œë„ {attempt} ì‹¤íŒ¨: {str(e)}")
                if attempt < max_retries:
                    print(f"   {3}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(3)
                else:
                    print("   âŒ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨!")
                    raise Exception("NTIS ì‚¬ì´íŠ¸ ì ‘ì† ì‹¤íŒ¨")
        
        time.sleep(2)  # ì¶”ê°€ ì•ˆì •í™” ëŒ€ê¸°
        
        # ì‹¤ì œ ì ‘ì†ëœ URL í™•ì¸
        current_url = driver.current_url
        print(f"   ğŸ“ ì‹¤ì œ URL: {current_url}")
        
        # í˜ì´ì§€ ì œëª© í™•ì¸
        page_title = driver.title
        print(f"   ğŸ“„ í˜ì´ì§€ ì œëª©: {page_title}")
        
        # ê²€ìƒ‰ì°½ í™•ì¸ (ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì…€ë ‰í„° ì‹œë„)
        search_found = False
        possible_search_selectors = [
            "input[placeholder*='í‚¤ì›Œë“œ']",
            "input[name='searchKeyword']", 
            "input[id='searchKeyword']",
            "input[type='text']"
        ]
        
        for selector in possible_search_selectors:
            try:
                search_element = driver.find_element(By.CSS_SELECTOR, selector)
                print(f"   âœ… ê²€ìƒ‰ì°½ ë°œê²¬! ì…€ë ‰í„°: {selector}")
                search_found = True
                break
            except:
                continue
        
        if not search_found:
            print("   âš ï¸ ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            # ê·¸ë˜ë„ ì§„í–‰í•´ë³´ê¸°
        
        print("   âœ… NTIS ì‚¬ì´íŠ¸ ì ‘ì† ì™„ë£Œ")
        
        # 3. ê²€ìƒ‰ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
        try:
            keywords = get_search_keywords()
            if keywords:
                keyword = keywords[0]  # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ì‚¬ìš©
                print(f"   ğŸ“ ì„¤ì • í‚¤ì›Œë“œ ì‚¬ìš©: {keyword}")
            else:
                keyword = "AI"
                print(f"   ğŸ“ ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©: {keyword}")
        except:
            keyword = "AI"
            print(f"   ğŸ“ ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©: {keyword}")
        
        # 4. í‚¤ì›Œë“œ ê²€ìƒ‰
        search_success = search_with_keyword(driver, keyword)
        
        if not search_success:
            print("âŒ ê²€ìƒ‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # 5. ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
        crawled_data = crawl_announcement_list(driver, target_count=30)
        
        if not crawled_data:
            print("âŒ í¬ë¡¤ë§ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return
        
        # 6. ë°ì´í„° ê´€ë¦¬ (ê¸°ì¡´ ë°ì´í„°ì™€ ë¹„êµ, ì‹ ê·œ í•­ëª© ì²˜ë¦¬)
        try:
            print("\nğŸ“Š ë°ì´í„° ê´€ë¦¬ ì‹œì‘...")
            os.makedirs("output", exist_ok=True)
            
            # ê¸°ì¡´ old_data.json ë¡œë“œ
            existing_data = []
            old_data_file = "output/old_data.json"
            if os.path.exists(old_data_file):
                with open(old_data_file, "r", encoding="utf-8") as f:
                    existing_data = json.load(f)
            print(f"   ğŸ“‚ ê¸°ì¡´ ë°ì´í„°: {len(existing_data)}ê°œ")
            
            # ê¸°ì¡´ ë°ì´í„°ì˜ roRndUid ì¶”ì¶œ
            existing_uids = set()
            for item in existing_data:
                uid = extract_uid_from_url(item.get("ìƒì„¸_URL", ""))
                if uid:
                    existing_uids.add(uid)
            
            # ì‹ ê·œ í•­ëª© ì°¾ê¸°
            new_items = []
            for item in crawled_data:
                uid = extract_uid_from_url(item.get("ìƒì„¸_URL", ""))
                if uid and uid not in existing_uids:
                    new_items.append(item)
            
            print(f"   ğŸ†• ì‹ ê·œ í•­ëª©: {len(new_items)}ê°œ")
            print(f"   ğŸ”„ ì¤‘ë³µ í•­ëª©: {len(crawled_data) - len(new_items)}ê°œ")
            
            # ì‹ ê·œ í•­ëª©ì´ ìˆìœ¼ë©´ ì²˜ë¦¬
            if new_items:
                # ê¸°ì¡´ + ì‹ ê·œ í•©ì¹˜ê¸°
                all_items = existing_data + new_items
                
                # ì ‘ìˆ˜ì¼ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
                def parse_date_for_sort(date_str):
                    try:
                        return datetime.strptime(date_str, "%Y.%m.%d")
                    except:
                        return datetime.min
                
                sorted_items = sorted(all_items, key=lambda x: parse_date_for_sort(x.get("ì ‘ìˆ˜ì¼", "")), reverse=True)
                
                # ìµœì‹  30ê°œë§Œ ìœ ì§€
                final_items = sorted_items[:30]
                
                # old_data.json ì—…ë°ì´íŠ¸ (ì „ì²´ 30ê°œ ì €ì¥)
                with open(old_data_file, "w", encoding="utf-8") as f:
                    json.dump(final_items, f, ensure_ascii=False, indent=2)
                print(f"   ğŸ’¾ ì „ì²´ ë°ì´í„° ì €ì¥: output/old_data.json ({len(final_items)}ê°œ)")
                
                # ì‹ ê·œ í•­ëª©ë§Œ ë³„ë„ ì €ì¥
                with open("output/new_data.json", "w", encoding="utf-8") as f:
                    json.dump(new_items, f, ensure_ascii=False, indent=2)
                print(f"   ğŸ†• ì‹ ê·œ ë°ì´í„° ì €ì¥: output/new_data.json ({len(new_items)}ê°œ)")
                
            else:
                print("   â„¹ï¸ ì‹ ê·œ í•­ëª©ì´ ì—†ì–´ ë°ì´í„° ì—…ë°ì´íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                # ì‹ ê·œ í•­ëª©ì´ ì—†ì–´ë„ old_data.jsonì€ ì—…ë°ì´íŠ¸ (í¬ë¡¤ë§ëœ ìµœì‹  30ê°œ)
                with open(old_data_file, "w", encoding="utf-8") as f:
                    json.dump(crawled_data[:30], f, ensure_ascii=False, indent=2)
                print(f"   ğŸ’¾ ì „ì²´ ë°ì´í„° ì—…ë°ì´íŠ¸: output/old_data.json ({len(crawled_data[:30])}ê°œ)")
                
                # new_data.jsonì€ ë¹ˆ ë°°ì—´ë¡œ ì´ˆê¸°í™”
                with open("output/new_data.json", "w", encoding="utf-8") as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                print(f"   ğŸ†• ì‹ ê·œ ë°ì´í„° ì—†ìŒ: output/new_data.json (0ê°œ)")
            
            print(f"\nğŸ“‹ ìµœì¢… ìš”ì•½:")
            print(f"   - í¬ë¡¤ë§ í•­ëª©: {len(crawled_data)}ê°œ")
            print(f"   - ì‹ ê·œ í•­ëª©: {len(new_items)}ê°œ")
            print(f"   - ì²˜ë¦¬ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ê´€ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            print("   í¬ë¡¤ë§ ë°ì´í„°ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
            
            # ê¸°ë³¸ JSON ì €ì¥
            with open("output/ntis_crawled_raw.json", "w", encoding="utf-8") as f:
                json.dump(crawled_data, f, ensure_ascii=False, indent=2)
            print("   ğŸ’¾ ì›ì‹œ ë°ì´í„° ì €ì¥: output/ntis_crawled_raw.json")
        
        print("\nğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    finally:
        if driver:
            print("\nğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘...")
            driver.quit()
            print("   âœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")

if __name__ == "__main__":
    main()